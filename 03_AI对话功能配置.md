# AI对话功能配置指南

## 功能概述

AI学习助手的AI功能通过Obsidian的Copilot插件实现，提供以下核心能力：

### 主要功能
- **多模型支持**：支持多种AI模型并行使用
- **智能检索**：通过Vault QA功能搜索仓库笔记，整合分散内容
- **快速操作**：提供一键翻译、润色、生成表格等功能
- **自定义指令**：用户可定制常用指令模板并快速调用

## 模型配置要求

AI学习助手正常运行需要配置两种模型：

### Chat Model (对话模型)
- **作用**：负责生成自然语言回答和对话交互
- **功能**：文本生成、问答、翻译、润色等
- **必需**：系统核心功能，必须配置

### Embedding Model (嵌入模型)  
- **作用**：将文本转换为向量，用于语义搜索
- **功能**：理解查询意图，检索相关文档
- **必需**：Vault QA功能，必须配置

## 模型部署选择

### 云端API部署（推荐初学者）
**优点**：
- 硬件要求低，任何电脑都可运行
- 运算速度快，响应及时
- 无需本地安装大型模型

**缺点**：
- 按使用收费（例如DeepSeek R1约4分钱/问题）
- 隐私考虑：嵌入模型会访问所有仓库文件
- 需要稳定网络连接

### 本地模型部署
**优点**：
- 完全私密，数据不外传
- 一次配置无使用成本
- 离线使用

**缺点**：
- 硬件要求高（推荐16GB+内存）
- 响应速度相对较慢
- 需要下载大型模型文件

## Chat Model配置步骤

### 第一步：打开配置页面
1. 进入Obsidian设置页面
2. 选择"第三方插件"
3. 找到并点击"Copilot"
4. 切换到"Model"标签页

### 第二步：添加自定义模型
1. 在"Chat Model"区域点击"Add Custom Model"按钮
2. 系统将弹出模型配置对话框

### 第三步：填写模型信息

#### 基础配置
- **Model Name**（必填）：输入准确的模型名称
  - 示例：`deepseek-ai/DeepSeek-R1`
  - 注意：必须与提供商模型名称完全一致

- **Display Name**（可选）：自定义显示名称
  - 示例：`Siliconflow_DeepSeek-R1`
  - 作用：在界面中的友好显示名称

#### 提供商配置
- **Provider**：选择API接口格式
  - **OpenAI Format**：适用于兼容OpenAI API的提供商（如硅基流动、DeepSeek等）
  - **Anthropic**：适用于Claude系列模型
  - **Google**：适用于Gemini系列模型

- **Base URL**：API服务地址
  - 硅基流动：`https://api.siliconflow.cn/v1`
  - DeepSeek：`https://api.deepseek.com/v1`
  - OpenAI官方：`https://api.openai.com/v1`
  - 本地LM Studio：`http://localhost:1234/v1`

#### 身份验证
- **API Key**：从模型提供商获取的访问密钥
  - 获取方式：在提供商官网注册账号，创建API密钥
  - 安全提醒：密钥仅显示一次，需妥善保存

#### 模型能力配置
必须勾选以下选项：
- **☑ Reasoning**：启用推理和问答能力
- **☑ Enable CORS**：允许跨域资源共享

### 第四步：验证配置
1. 点击"Verify"按钮测试连接
2. 等待验证结果：
   - 成功：右上角显示"Model verification successful"
   - 失败：检查配置信息并重新填写

### 第五步：添加模型
1. 验证成功后点击"Add Model"按钮
2. 模型将出现在Chat Model列表中

### 第六步：启用模型
在模型列表中勾选：
- **☑ Enable**：激活模型使用
- **☑ CORS**：确保跨域访问正常

## Embedding Model配置

### 配置流程
Embedding Model的配置步骤与Chat Model基本相同，区别在于：

1. 在"Embedding Model"区域操作
2. 模型选择建议：
   - **BAAI/bge-large-zh-v1.5**：适合中文内容
   - **text-embedding-ada-002**：OpenAI官方模型
   - **nomic-embed-text**：适合本地部署

### 推荐配置
- **提供商**：选择与Chat Model相同的提供商
- **API设置**：使用相同的Base URL和API Key
- **注意事项**：不要在建立索引后更换Embedding模型，会导致检索功能异常

## 模型参数调整

### Temperature (温度参数)
- **取值范围**：0.0 - 1.0
- **推荐设置**：
  - **学术问答**：0.1-0.3（更准确一致）
  - **创意写作**：0.7-0.9（更有创造性）
  - **日常对话**：0.5-0.7（平衡准确性和多样性）

### Token Limit (令牌限制)
- **作用**：控制模型单次处理的最大文本长度
- **设置建议**：根据模型支持的最大上下文长度设置
- **注意事项**：设置过高可能影响响应速度和成本

### Conversation Turns (对话轮数)
- **作用**：系统保持的历史对话轮数
- **推荐设置**：3-5轮（平衡记忆和性能）
- **影响**：设置过高会增加API调用成本

## 常见问题排查

### 模型验证失败
**可能原因**：
- API Key错误或过期
- Base URL地址不正确
- 网络连接问题
- 模型名称拼写错误

**解决方法**：
1. 检查API Key是否有效
2. 验证Base URL格式和网络可达性
3. 确认模型名称与提供商一致
4. 测试网络连接稳定性

### 对话无响应
**可能原因**：
- 模型未正确启用
- API配额不足
- 网络请求超时

**解决方法**：
1. 确认Enable和CORS选项已勾选
2. 检查API账户余额和配额
3. 调整网络设置或更换网络环境

### 检索功能异常
**可能原因**：
- Embedding模型配置错误
- 仓库索引需要更新
- 模型切换导致索引失效

**解决方法**：
1. 验证Embedding模型配置
2. 重新构建仓库索引
3. 避免频繁更换Embedding模型

## 相关文档

- [[AI学习助手概念术语表]] - 了解相关技术概念
- [[本地模型部署指南]] - LM Studio本地部署方法
- [[API服务商选择]] - 各大云端AI服务对比
- [[常见问题解答]] - 更多故障排除方法