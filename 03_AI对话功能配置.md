# AI对话功能配置指南

## Q：AI学习助手的AI功能是如何实现的？

**A**：AI学习助手的AI功能通过Obsidian的Copilot插件实现，提供以下核心能力：
- **多模型支持**：支持多种AI模型并行使用
- **智能检索**：通过Vault QA功能搜索仓库笔记，整合分散内容
- **快速操作**：提供一键翻译、润色、生成表格等功能
- **自定义指令**：用户可定制常用指令模板并快速调用

## Q：需要配置哪两种模型？

**A**：AI学习助手正常运行需要配置两种模型：

### Chat Model (对话模型)
- **作用**：负责生成自然语言回答和对话交互
- **功能**：文本生成、问答、翻译、润色等
- **必需**：系统核心功能，必须配置

### Embedding Model (嵌入模型)  
- **作用**：将文本转换为向量，用于语义搜索
- **功能**：理解查询意图，检索相关文档
- **必需**：Vault QA功能，必须配置

## Q：应该选择云端API还是本地模型？

**A**：根据需求选择：

### 云端API部署（推荐初学者）
**优点**：
- 硬件要求低，任何电脑都可运行
- 运算速度快，响应及时
- 无需本地安装大型模型

**缺点**：
- 按使用收费（例如DeepSeek R1约4分钱/问题）
- 隐私考虑：嵌入模型会访问所有仓库文件
- 需要稳定网络连接

### 本地模型部署
**优点**：
- 完全私密，数据不外传
- 一次配置无使用成本
- 离线使用

**缺点**：
- 硬件要求高（推荐16GB+内存）
- 响应速度相对较慢
- 需要下载大型模型文件

## Q：推荐使用哪些云端API服务？

**A**：推荐配置：

### Chat Model推荐
1. **DeepSeek R1（推荐）**
   - 模型名：deepseek-reasoner
   - 费用：约2分钱/千字输出
   - 特点：强大推理能力，性价比高

2. **Google Gemini Flash（推荐）**
   - 模型名：gemini-2.0-flash-thinking-exp
   - 费用：免费使用
   - 特点：速度快，适合日常对话

3. **百度千帆大模型**
   - 国内服务，无需翻墙
   - 适合隐私要求高的用户

### Embedding Model推荐
**Qwen3-Embedding-4B（推荐）**
- 提供商：硅基流动SiliconFlow
- 模型名：Qwen/Qwen3-Max-Embedding-4B
- 费用：免费使用
- 特点：检索效果好，速度快

## Q：如何配置DeepSeek API？

**A**：
1. 访问 https://platform.deepseek.com/
2. 注册账号并登录
3. 在API Keys页面创建新密钥
4. 复制API密钥
5. 在Copilot设置中：
   - API Provider: 选择"DeepSeek"
   - API Key: 粘贴密钥
   - Model: 选择"deepseek-reasoner"
6. 点击"检查API连接"验证配置

## Q：如何配置硅基流动嵌入模型？

**A**：
1. 访问 https://cloud.siliconflow.cn/
2. 注册并登录账号
3. 在API管理页面创建API密钥
4. 在Copilot设置的Embedding配置中：
   - Provider: "Other (OpenAI-compatible)"
   - Endpoint: https://api.siliconflow.cn/v1
   - API Key: 粘贴密钥
   - Model: Qwen/Qwen3-Max-Embedding-4B
5. 点击"Rebuild entire vault index"重建索引

## Q：如何配置本地模型？

**A**：使用LM Studio配置本地模型：
1. 下载安装LM Studio
2. 在LM Studio中下载模型（如Qwen 2.5）
3. 启动本地服务器（端口1234）
4. 在Copilot设置中配置本地服务地址
5. 详细步骤参考[[本地模型部署指南]]

## Q：如何配置语音识别功能？

**A**：ASR语音识别配置步骤：
1. 在AI学习助手启动器安装语音服务包
2. 启动ASR服务（端口9000）
3. 在Copilot插件设置中选择"Local Service"
4. 配置端口为9000，开启encode与VAD选项

使用方式：
- 右键菜单选择"Open recording controls"进行录音
- 右键音视频文件选择"🎧Transcribe"进行转录
- 在Copilot对话框点击voice按钮进行语音输入

## Q：如何配置文字转语音功能？

**A**：TTS文字转语音配置步骤：
1. 在AI学习助手启动器安装语音服务包
2. 启动TTS服务（端口8000）
3. 在Aloud插件设置中选择"OpenAI Compatible"
4. 配置API URL为http://localhost:8000
5. Model填写kokoro（CPU）或index-tts（GPU）

音色模型对比：
- **kokoro**：CPU/GPU可用，速度快，音质中规中矩
- **index-tts**：GPU速度快，音质高，支持音色克隆

## Q：如何使用自动衍生问题功能？

**A**：
1. 在Copilot设置中开启"自动衍生问题"
2. 可自定义衍生问题提示词
3. AI会根据对话内容自动生成相关学习问题
4. 与自动语音播放配合使用效果更佳

## Q：配置完成后如何测试？

**A**：
1. 打开任意笔记
2. 点击右侧Copilot图标
3. 输入简单问题测试Chat Model
4. 使用Vault QA功能测试Embedding Model
5. 如遇问题，检查API密钥和网络连接

## Q：常见配置问题如何解决？

**A**：
- **API连接失败**：检查密钥是否正确，网络是否稳定
- **Vault QA无结果**：验证Embedding模型配置，重新构建索引
- **响应速度慢**：考虑更换模型或使用云端API
- **费用担心**：先使用免费模型熟悉功能

## Q：需要查看哪些相关文档？

**A**：
- [[AI学习助手概念术语表]] - 了解相关技术概念
- [[本地模型部署指南]] - LM Studio本地部署方法
- [[API服务商选择]] - 各大云端AI服务对比
- [[常见问题解答]] - 更多故障排除方法
- [[语音功能使用指南]] - 语音功能详细教程