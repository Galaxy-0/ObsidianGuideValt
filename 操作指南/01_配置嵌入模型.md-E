# 如何配置嵌入模型

## 操作目标
为AI学习助手配置Embedding Model，实现智能检索和Vault QA功能。

## 前置条件
- 已完成Chat Model配置
- 已获取API Key
- 确保网络连接正常

## 详细步骤

### 第一步：进入配置页面
1. 打开Obsidian设置（点击左下角齿轮图标）
2. 选择"第三方插件"选项
3. 在插件列表中找到"Copilot"
4. 点击进入Copilot配置页面
5. 切换到"Model"标签页

### 第二步：添加嵌入模型
1. 找到页面上的"Embedding Model"区域
2. 点击该区域下方的"Add Custom Model"按钮
3. 系统弹出嵌入模型配置对话框

### 第三步：填写模型信息

#### 模型名称配置
- **Model Name**：输入准确的嵌入模型名称
  - 硅基流动推荐：`Qwen/Qwen3-Embedding-4B`（2024年最新，MTEB多语言排行榜第一）
  - 硅基流动备选：`BAAI/bge-large-zh-v1.5`
  - OpenAI推荐：`text-embedding-ada-002` 
  - 本地部署：`nomic-embed-text`

- **Display Name**：设置友好的显示名称
  - 示例：`Qwen3-Embedding-4B`或`BGE-Large-中文嵌入模型`

#### 提供商和API配置
- **Provider**：选择API格式
  - 硅基流动等：选择"OpenAI Format"
  - OpenAI官方：选择"OpenAI"

- **Base URL**：设置API地址
  - 硅基流动：`https://api.siliconflow.cn/v1`
  - OpenAI：`https://api.openai.com/v1`

- **API Key**：输入在提供商处获取的API密钥

### 第四步：验证和添加
1. 点击"Verify"按钮测试连接
2. 等待验证结果显示在右上角
3. 验证成功后点击"Add Model"按钮
4. 模型添加到Embedding Model列表

### 第五步：启用模型
1. 在Embedding Model列表中找到刚添加的模型
2. 勾选"Enable"选项启用模型
3. 确保"CORS"选项也已勾选

## 重要注意事项

### 模型选择建议
- **中文内容为主**：推荐`Qwen/Qwen3-Embedding-4B`（2024年最新，性能最佳）
- **英文内容为主**：推荐`text-embedding-ada-002`
- **混合内容**：推荐`Qwen/Qwen3-Embedding-4B`（支持100+语言）
- **备选方案**：`BAAI/bge-large-zh-v1.5`（如遇到兼容性问题）

### 配置后处理
1. **重建索引**：更换嵌入模型后需要重新构建仓库索引
2. **避免频繁更换**：嵌入模型确定后尽量不要更改
3. **测试功能**：配置完成后测试Vault QA功能是否正常

## 常见问题解决

### 验证失败
**可能原因**：
- API Key错误或已过期
- 模型名称拼写错误
- 网络连接问题
- 模型不兼容或已停用

**解决方法**：
1. 检查API Key是否正确且有效
2. 验证模型名称与提供商一致（如`Qwen/Qwen3-Embedding-4B`）
3. 测试网络连接和API地址可达性
4. 如遇到兼容性问题，可尝试备选模型`BAAI/bge-large-zh-v1.5`

### 检索功能异常
**可能原因**：
- 索引未更新
- 模型未正确启用
- 仓库文件发生变化

**解决方法**：
1. 手动运行"Index vault for QA"命令
2. 确认Enable和CORS选项已勾选
3. 重新构建完整索引

## 验证配置成功

### 测试步骤
1. 在Copilot面板中切换到"Vault QA"模式
2. 提问一个关于仓库内容的具体问题
3. 观察是否能正确检索和引用相关文档
4. 检查回答中是否包含文档来源链接

### 成功标志
- 能够根据查询检索到相关文档片段
- 回答包含准确的文档引用和页面链接
- 检索结果与查询内容高度相关

## 相关文档
- [[03_AI对话功能配置]] - Chat Model配置方法
- [[01_概念术语表]] - 了解嵌入模型的作用
- [[04_常见问题解答]] - 更多故障排除方法